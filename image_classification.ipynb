{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/birajsth/MachineLearning-with-tensorflow/blob/master/image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pyHzJ_7nL__",
        "colab_type": "text"
      },
      "source": [
        "# Image Classification\n",
        "Building an image classifier from scratch to distinguish photos of cats from photos of dogs using Conbolutional Neural Network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX8LckV_n_cV",
        "colab_type": "text"
      },
      "source": [
        "**Explore the Example Data**\n",
        "\n",
        "The 2,000 images used in this exercise are excerpted from ' Dogs vs Cats' dataset available on kaggle, which contains 25,000 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c4qW0CUn9pK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "6ca73156-6530-447a-e39a-8ec8461c8336"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-10 07:23:57--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 2607:f8b0:400e:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  82.6MB/s    in 0.8s    \n",
            "\n",
            "2019-05-10 07:23:58 (82.6 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou4uwgfTopBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4thXstNpFrT",
        "colab_type": "text"
      },
      "source": [
        "The contents of the .zip are extracted to the vase directory /tmp/cats_and_dogs_filtered, which contains train and  validation subdirectories for the training and validation datasets, which in turn each contain cats and dogs subdirectories. Let's define each of these directories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv1HYbL5ppzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directories with our training cat and dog pictures.\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directories with our validation cat and dog pictures.\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ft2thInrGJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5a2c1766-58ea-4d2a-b666-31d34af8a391"
      },
      "source": [
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "print(train_cat_fnames[:10])\n",
        "\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "train_dog_fnames.sort()\n",
        "print(train_dog_fnames[:10])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cat.451.jpg', 'cat.436.jpg', 'cat.816.jpg', 'cat.91.jpg', 'cat.673.jpg', 'cat.300.jpg', 'cat.873.jpg', 'cat.845.jpg', 'cat.958.jpg', 'cat.204.jpg']\n",
            "['dog.0.jpg', 'dog.1.jpg', 'dog.10.jpg', 'dog.100.jpg', 'dog.101.jpg', 'dog.102.jpg', 'dog.103.jpg', 'dog.104.jpg', 'dog.105.jpg', 'dog.106.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HlqN5KbafhLI"
      },
      "source": [
        "Let's find out the total number of cat and dog images in the `train` and `validation` directories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR6EocAyrzxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "95cf6afe-8858-4e0b-e9de-f2f508834d27"
      },
      "source": [
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training cat images: 1000\n",
            "total training dog images: 1000\n",
            "total validation cat images: 500\n",
            "total validation dog images: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C3WZABE9eX-8"
      },
      "source": [
        "For both cats and dogs, we have 1,000 training images and 500 test images.\n",
        "\n",
        "Now let's take a look at a few pictures to get a better sense of what the cat and dog datasets look like. First, configure the matplot parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_at2ul1RsRnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Parameters for our graph;\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "# Index for iterating over images\n",
        "pic_index = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xTvHzGCxXkqp"
      },
      "source": [
        "Now, display a batch of 8 cat and 8 dog pictures. You can rerun the cell to see a fresh batch each time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkTLx3IhtDMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up matplotlib fig, and size it to fit 4x4 pics.\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index += 8\n",
        "next_cat_pix = [os.path.join(train_cats_dir, fname)\n",
        "                for fname in train_cat_fnames[pic_index-8:pic_index]]\n",
        "next_dog_pix = [os.path.join(train_dogs_dir, fname)\n",
        "                for fname in train_dog_fnames[pic_index-8:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows, ncols, i+1)\n",
        "  sp.axis('OFF')\n",
        "  \n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "  \n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mQs_d5Svadu",
        "colab_type": "text"
      },
      "source": [
        "## Building a Small Convnet from scratch to get to 72% accuracy\n",
        "The images that will fo into our convnet are 150x150 color imagesl\n",
        "\n",
        "Let's code up the architecture. We will stack 3 {convolution + relu + maxpooling} modules.\n",
        "Our convolutions operate on 3x3 windows and our maxpooling layres operate on 2x2 windows. Our first convolution extracts 16 filters, the following one extracts 32 filters, and the last one extracts 64 filters.\n",
        "\n",
        "Note: This is a configuration that is widely used and known to work for image classification. Also, since we have relatively few training examples(1,000),  using just three convolutional modules keeps the model small, which lowers the risk of overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stCv0_yHxDBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vJYFXWaxfQH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c1ed491d-a8b5-434b-de6f-432f8aa5b6c5"
      },
      "source": [
        "# Our input feature map is 150x150x3 for the image pixels, and 3 for the \n",
        "# three color channels: R, G, and B.\n",
        "img_input = layers.Input(shape=(150, 150, 3))\n",
        "\n",
        "# First convolution extracts 16 filters that are 3x3\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\n",
        "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "# Second convolution extracts 32 filters that are 3x3\n",
        "x = layers.Conv2D(32, 3, activation='relu')(img_input)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "# Third convolution extracts 64 filters that are 3x3\n",
        "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D(2)(x)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DxOO9WKzl56",
        "colab_type": "text"
      },
      "source": [
        "On top of it we stick two fully-connected layers. Because we are facing a two-class classification problem , i.e a binary classification problem, we will end our network with a sigmoid activation, so that the output of our network will be a single scalar between 0 and 1, encoding the probability that the current image is class 1 (as opposed to class 0.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05TZisX80QrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Flatten feature map to a 1-dim tensor so we can add fully connected layer\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "# Create a fully connected layer with ReLU activation and 512 hidden units\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "\n",
        "# Create output layer with a singel node and sigmoid activation\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create Model:\n",
        "# input = input feature map\n",
        "# output = input feature map + stacked convolution/maxpooling layers + \n",
        "# fully connected layer + sigmoid output layer\n",
        "model = Model(img_input, output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX7G6JF41kmI",
        "colab_type": "text"
      },
      "source": [
        "Let's summarize the model architecture:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0DMulWm1pel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "17a467e1-a3aa-48f3-87e3-c401c7155ddd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 82944)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               42467840  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 42,750,401\n",
            "Trainable params: 42,750,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}